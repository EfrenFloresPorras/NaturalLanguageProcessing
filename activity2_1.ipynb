{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 820 entries, 0 to 819\n",
      "Data columns (total 4 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Unnamed: 0     820 non-null    int64 \n",
      " 1   review_title   820 non-null    object\n",
      " 2   review_text    819 non-null    object\n",
      " 3   review_rating  820 non-null    object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 25.8+ KB\n",
      "None\n",
      "\n",
      "Dataset Description:\n",
      "       Unnamed: 0\n",
      "count  820.000000\n",
      "mean   409.500000\n",
      "std    236.857904\n",
      "min      0.000000\n",
      "25%    204.750000\n",
      "50%    409.500000\n",
      "75%    614.250000\n",
      "max    819.000000\n",
      "\n",
      "Missing Values:\n",
      "Unnamed: 0       0\n",
      "review_title     0\n",
      "review_text      1\n",
      "review_rating    0\n",
      "dtype: int64\n",
      "SVM Model:\n",
      "Best Parameters: {'C': 1, 'kernel': 'linear'}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.52      0.62        50\n",
      "           1       0.82      0.93      0.87       114\n",
      "\n",
      "    accuracy                           0.80       164\n",
      "   macro avg       0.79      0.72      0.74       164\n",
      "weighted avg       0.80      0.80      0.79       164\n",
      "\n",
      "Accuracy: 0.8048780487804879\n",
      "\n",
      "Decision Tree Model:\n",
      "Best Parameters: {'max_depth': 20, 'min_samples_split': 5}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.48      0.58        50\n",
      "           1       0.80      0.92      0.86       114\n",
      "\n",
      "    accuracy                           0.79       164\n",
      "   macro avg       0.76      0.70      0.72       164\n",
      "weighted avg       0.78      0.79      0.77       164\n",
      "\n",
      "Accuracy: 0.7865853658536586\n",
      "\n",
      "Logistic Regression Model:\n",
      "Best Parameters: {'C': 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.50      0.62        50\n",
      "           1       0.81      0.95      0.87       114\n",
      "\n",
      "    accuracy                           0.81       164\n",
      "   macro avg       0.81      0.72      0.75       164\n",
      "weighted avg       0.81      0.81      0.80       164\n",
      "\n",
      "Accuracy: 0.8109756097560976\n",
      "\n",
      "Random Forest Classifier Model:\n",
      "Best Parameters: {'criterion': 'entropy', 'max_depth': None, 'max_leaf_nodes': None, 'n_estimators': 100}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.48      0.59        50\n",
      "           1       0.80      0.94      0.87       114\n",
      "\n",
      "    accuracy                           0.80       164\n",
      "   macro avg       0.79      0.71      0.73       164\n",
      "weighted avg       0.80      0.80      0.78       164\n",
      "\n",
      "Accuracy: 0.7987804878048781\n",
      "\n",
      "\n",
      "Model Comparison:\n",
      "                 Model  Accuracy\n",
      "0                  SVM  0.804878\n",
      "1        Decision Tree  0.786585\n",
      "2  Logistic Regression  0.810976\n",
      "3        Random Forest  0.798780\n"
     ]
    }
   ],
   "source": [
    "def sentiment_analysis(file_path):\n",
    "    # Load the dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Data Understanding\n",
    "    def data_understanding(df):\n",
    "        print(\"Dataset Information:\")\n",
    "        print(df.info())\n",
    "\n",
    "        print(\"\\nDataset Description:\")\n",
    "        print(df.describe())\n",
    "\n",
    "        # Check for missing values\n",
    "        print(\"\\nMissing Values:\")\n",
    "        print(df.isnull().sum())\n",
    "\n",
    "    data_understanding(df)\n",
    "\n",
    "    # Data Preprocessing\n",
    "    def data_preprocessing(df):\n",
    "        # Drop rows with missing values (if any)\n",
    "        df.dropna(inplace=True)\n",
    "\n",
    "        # Convert review_rating to numerical values using str.extract\n",
    "        df['review_rating'] = df['review_rating'].str.extract('(\\\\d+)').astype(int)\n",
    "\n",
    "        # Create a new column 'sentiment' with positive (1) for ratings >= 4 and negative (0) for ratings < 4\n",
    "        df['sentiment'] = df['review_rating'].apply(lambda x: 1 if x >= 4 else 0)\n",
    "\n",
    "        # Pre-process the data using CountVectorizer\n",
    "        vectorizer = CountVectorizer(stop_words='english')\n",
    "        X = vectorizer.fit_transform(df['review_text'])\n",
    "        y = df['sentiment']\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    X, y = data_preprocessing(df)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Define a function to perform grid search and evaluate models\n",
    "    def evaluate_model(model, param_grid):\n",
    "        grid_search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        print(f\"Best Parameters: {grid_search.best_params_}\")\n",
    "        print(f\"Classification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "        print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\\n\")\n",
    "        return best_model\n",
    "\n",
    "    # SVM Model\n",
    "    def svm_model():\n",
    "        print(\"SVM Model:\")\n",
    "        svm_param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
    "        return evaluate_model(svm.SVC(), svm_param_grid)\n",
    "\n",
    "    # Decision Tree Model\n",
    "    def dt_model():\n",
    "        print(\"Decision Tree Model:\")\n",
    "        dt_param_grid = {'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10]}\n",
    "        return evaluate_model(DecisionTreeClassifier(), dt_param_grid)\n",
    "\n",
    "    # Logistic Regression Model\n",
    "    def lr_model():\n",
    "        print(\"Logistic Regression Model:\")\n",
    "        lr_param_grid = {'C': [0.1, 1, 10]}\n",
    "        return evaluate_model(LogisticRegression(), lr_param_grid)\n",
    "\n",
    "    # Random Forest Classifier Model\n",
    "    def rf_model():\n",
    "        print(\"Random Forest Classifier Model:\")\n",
    "        rf_param_grid = {\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'criterion': ['gini', 'entropy'],\n",
    "            'max_depth': [None, 10, 20],\n",
    "            'max_leaf_nodes': [None, 10, 20]\n",
    "        }\n",
    "        return evaluate_model(RandomForestClassifier(), rf_param_grid)\n",
    "\n",
    "    # Train and evaluate each model\n",
    "    svm_best_model = svm_model()\n",
    "    dt_best_model = dt_model()\n",
    "    lr_best_model = lr_model()\n",
    "    rf_best_model = rf_model()\n",
    "\n",
    "    # Compare the performance of each model\n",
    "    models = ['SVM', 'Decision Tree', 'Logistic Regression', 'Random Forest']\n",
    "    accuracies = [\n",
    "        accuracy_score(y_test, svm_best_model.predict(X_test)),\n",
    "        accuracy_score(y_test, dt_best_model.predict(X_test)),\n",
    "        accuracy_score(y_test, lr_best_model.predict(X_test)),\n",
    "        accuracy_score(y_test, rf_best_model.predict(X_test))\n",
    "    ]\n",
    "\n",
    "    comparison_df = pd.DataFrame({'Model': models, 'Accuracy': accuracies})\n",
    "    print(\"\\nModel Comparison:\")\n",
    "    print(comparison_df)\n",
    "\n",
    "# Call the function with the path to your dataset\n",
    "sentiment_analysis('archives/kaggle.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvNaturalLenguageProcessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
