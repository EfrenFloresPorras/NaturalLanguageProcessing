{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import numpy as np # to use numpy arrays instead of lists\n",
    "import pandas as pd # DataFrame (table)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData():\n",
    "\n",
    "    dataSet = pd.read_csv('archives/archive1.zip', header = 0, compression = 'zip')\n",
    "    return dataSet\n",
    "\n",
    "def encodeData(dataSet):\n",
    "\n",
    "    dataSet.dropna(inplace=True)\n",
    "\n",
    "    # Dropping irrelevant columns 'Year', 'Month', 'Day', 'Time of Tweet', 'Platform' \n",
    "    dataSet.drop(['Year', 'Month', 'Day', 'Time of Tweet', 'Platform'], axis=1, inplace=True)\n",
    "\n",
    "    # Add 'neutral' sentiment to 'negative' sentiment\n",
    "    dataSet['sentiment'] = dataSet['sentiment'].replace('neutral', 'negative')\n",
    "\n",
    "    # mapping the sentiment to 0 and 1\n",
    "    dataSet['sentiment'] = dataSet['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "    return dataSet\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "def splitData(dataSet):\n",
    "\n",
    "    X = dataSet['text']\n",
    "    y = dataSet['sentiment']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# Vectorize the data | Proccess the data\n",
    "def vectorizeData(X_train, X_test):\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(max_features=1000)\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    X_test = vectorizer.transform(X_test)\n",
    "    return [X_train, X_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metodosML(train_vectors, y_train, test_vectors, y_test):\n",
    "    methodsUsed = ['SVM', 'DT', 'LR', 'RF', 'NN']\n",
    "    performanceHeaders = ['precision', 'recall', 'f1-score']\n",
    "    modPerformancePos = pd.DataFrame(index=methodsUsed, columns=performanceHeaders)\n",
    "    modPerformanceNeg = pd.DataFrame(index=methodsUsed, columns=performanceHeaders)\n",
    "\n",
    "    # SVM\n",
    "    print('Classification with SVM')\n",
    "    svm_clf = svm.SVC()\n",
    "    param_search_svm = {'kernel': [\"poly\"], 'degree': [1, 2, 3, 4], 'coef0': [1, 2]}\n",
    "    grid_search_svm = GridSearchCV(estimator=svm_clf, param_grid=param_search_svm, cv=5, verbose=1)\n",
    "    grid_search_svm.fit(train_vectors, y_train)\n",
    "    best_clf_svm = grid_search_svm.best_estimator_\n",
    "    svm_prediction = best_clf_svm.predict(test_vectors)\n",
    "    report = classification_report(y_test, svm_prediction, output_dict=True)\n",
    "    modPerformancePos.loc['SVM'] = [report['1']['precision'], report['1']['recall'], report['1']['f1-score']]\n",
    "    modPerformanceNeg.loc['SVM'] = [report['0']['precision'], report['0']['recall'], report['0']['f1-score']]\n",
    "    print(\"SVM accuracy: \", round(report['accuracy'], 2))\n",
    "\n",
    "    # Decision Tree\n",
    "    print('Classification with DT')\n",
    "    dt_clf = DecisionTreeClassifier()\n",
    "    param_search_clf = {'criterion': [\"gini\", 'entropy'], 'max_depth': [5, 10, 20, 30, None]}\n",
    "    grid_search_dt = GridSearchCV(estimator=dt_clf, param_grid=param_search_clf, cv=5, verbose=1)\n",
    "    grid_search_dt.fit(train_vectors, y_train)\n",
    "    best_clf_dt = grid_search_dt.best_estimator_\n",
    "    dt_prediction = best_clf_dt.predict(test_vectors)\n",
    "    report = classification_report(y_test, dt_prediction, output_dict=True)\n",
    "    modPerformancePos.loc['DT'] = [report['1']['precision'], report['1']['recall'], report['1']['f1-score']]\n",
    "    modPerformanceNeg.loc['DT'] = [report['0']['precision'], report['0']['recall'], report['0']['f1-score']]\n",
    "    print(\"DT accuracy: \", round(report['accuracy'], 2))\n",
    "\n",
    "    # Logistic Regression\n",
    "    print('Classification with Logistic Regression')\n",
    "    lr_clf = LogisticRegression(max_iter=1000)\n",
    "    lr_clf.fit(train_vectors, y_train)\n",
    "    lr_prediction = lr_clf.predict(test_vectors)\n",
    "    report = classification_report(y_test, lr_prediction, output_dict=True)\n",
    "    modPerformancePos.loc['LR'] = [report['1']['precision'], report['1']['recall'], report['1']['f1-score']]\n",
    "    modPerformanceNeg.loc['LR'] = [report['0']['precision'], report['0']['recall'], report['0']['f1-score']]\n",
    "    print(\"LR accuracy: \", round(report['accuracy'], 2))\n",
    "\n",
    "    # Random Forest\n",
    "    print('Classification with Random Forest')\n",
    "    rf_clf = RandomForestClassifier(n_estimators=100)\n",
    "    rf_clf.fit(train_vectors, y_train)\n",
    "    rf_prediction = rf_clf.predict(test_vectors)\n",
    "    report = classification_report(y_test, rf_prediction, output_dict=True)\n",
    "    modPerformancePos.loc['RF'] = [report['1']['precision'], report['1']['recall'], report['1']['f1-score']]\n",
    "    modPerformanceNeg.loc['RF'] = [report['0']['precision'], report['0']['recall'], report['0']['f1-score']]\n",
    "    print(\"RF accuracy: \", round(report['accuracy'], 2))\n",
    "\n",
    "    # Neural Network\n",
    "    print('Classification with Neural Network')\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, activation='relu', input_shape=(train_vectors.shape[1],)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Display model summary\n",
    "    model.summary()\n",
    "\n",
    "    # Train the model and plot training history\n",
    "    history = model.fit(train_vectors.toarray(), y_train, epochs=5, batch_size=512, validation_split=0.1, verbose=1)\n",
    "\n",
    "    # Plot training & validation accuracy values\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    # Plot training & validation loss values\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    nn_prediction = (model.predict(test_vectors.toarray()) > 0.5).astype(\"int32\")\n",
    "    report = classification_report(y_test, nn_prediction, output_dict=True)\n",
    "    modPerformancePos.loc['NN'] = [report['1']['precision'], report['1']['recall'], report['1']['f1-score']]\n",
    "    modPerformanceNeg.loc['NN'] = [report['0']['precision'], report['0']['recall'], report['0']['f1-score']]\n",
    "    print(\"NN accuracy: \", round(report['accuracy'], 2))\n",
    "\n",
    "    print(modPerformancePos)\n",
    "    print(modPerformanceNeg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification with SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "SVM accuracy:  0.82\n",
      "Classification with DT\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "DT accuracy:  0.79\n",
      "Classification with Logistic Regression\n",
      "LR accuracy:  0.73\n",
      "Classification with Random Forest\n",
      "RF accuracy:  0.86\n",
      "Classification with Neural Network\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\efren\\Documents\\GitHub\\venvNaturalLenguageProcessing\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.5432 - loss: 0.6923 - val_accuracy: 0.6250 - val_loss: 0.6817\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6630 - loss: 0.6734 - val_accuracy: 0.6250 - val_loss: 0.6727\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6741 - loss: 0.6604 - val_accuracy: 0.6250 - val_loss: 0.6647\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6741 - loss: 0.6465 - val_accuracy: 0.6250 - val_loss: 0.6581\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.6741 - loss: 0.6307 - val_accuracy: 0.6250 - val_loss: 0.6526\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "NN accuracy:  0.66\n",
      "\n",
      "Positive Sentiment\n",
      "    precision    recall  f1-score\n",
      "SVM  0.863636  0.558824  0.678571\n",
      "DT    0.69697  0.676471  0.686567\n",
      "LR        1.0  0.205882  0.341463\n",
      "RF        1.0  0.588235  0.740741\n",
      "NN        0.0       0.0       0.0\n",
      "\n",
      "Negative Sentiment\n",
      "    precision    recall  f1-score\n",
      "SVM  0.807692  0.954545     0.875\n",
      "DT   0.835821  0.848485  0.842105\n",
      "LR   0.709677       1.0  0.830189\n",
      "RF      0.825       1.0   0.90411\n",
      "NN       0.66       1.0  0.795181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\efren\\Documents\\GitHub\\venvNaturalLenguageProcessing\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\efren\\Documents\\GitHub\\venvNaturalLenguageProcessing\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\efren\\Documents\\GitHub\\venvNaturalLenguageProcessing\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    datos = readData()\n",
    "    encodeDatos = encodeData(datos)\n",
    "    X_train, X_test, y_train, y_test = splitData(encodeDatos)\n",
    "    train_vectors, test_vectors = vectorizeData(X_train, X_test)\n",
    "    metodosML(train_vectors, y_train, test_vectors, y_test)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables and Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvNaturalLenguageProcessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
