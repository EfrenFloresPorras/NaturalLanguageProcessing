{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0223214 - Efren Flores Porras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    datos = leeDatos()\n",
    "    print(datos)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    encodeDatos = encodeData(datos)\n",
    "    print(encodeDatos)\n",
    "    print(\"\\n\")\n",
    "    print(encodeDatos['Positively Rated'].mean())\n",
    "    print(\"\\n\")\n",
    "\n",
    "    ts_size = .25\n",
    "    [trainSet, testSet] = splitDataSet(encodeDatos, test_size=ts_size)\n",
    "    print(trainSet)\n",
    "    print('trainSet shape: ', trainSet.shape)\n",
    "    print(testSet)\n",
    "    print('testSet shape: ', testSet.shape)\n",
    "    print(\"\\n\")\n",
    "\n",
    "    [train_vectors, test_vectors] = processData(trainSet, testSet)\n",
    "\n",
    "    metodosML(train_vectors, trainSet, test_vectors, testSet)\n",
    "\n",
    "def leeDatos():\n",
    "    dataSet = pd.read_csv(\"archives/Sentiment_Stock_data.csv\", header=0)\n",
    "    return dataSet\n",
    "\n",
    "def encodeData(dataSet=0):\n",
    "    dataSet.dropna(inplace=True)\n",
    "\n",
    "    # Encode 1s as rated positively\n",
    "    # Encode 0 as rated poorly\n",
    "    dataSet['Positively Rated'] = np.where(dataSet['Sentiment'] == 1, 1, 0)\n",
    "    datos = ['Sentence', 'Positively Rated']\n",
    "    misDatos = dataSet[datos]\n",
    "    misDatos = misDatos.iloc[0:10000, :]\n",
    "\n",
    "    return misDatos\n",
    "\n",
    "def splitDataSet(dataSet=0, test_size=.2):\n",
    "    \"\"\"\n",
    "    Split data in train and test sets\n",
    "    \"\"\"\n",
    "    train, test = train_test_split(dataSet, test_size=test_size, random_state=0)\n",
    "    return [train, test]\n",
    "\n",
    "def processData(trainSet=0, testSet=0):\n",
    "    # Create feature vectors\n",
    "    vectorizer = TfidfVectorizer(stop_words='english',\n",
    "                                 min_df=5,\n",
    "                                 max_df=0.8,\n",
    "                                 sublinear_tf=True,\n",
    "                                 use_idf=True)\n",
    "    train_vectors = vectorizer.fit_transform(trainSet['Sentence'])\n",
    "    test_vectors = vectorizer.transform(testSet['Sentence'])\n",
    "    return [train_vectors, test_vectors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metodosML(train_vectors=0, trainSet=0, test_vectors=0, testSet=0):\n",
    "    methodsUsed = ['SVM', 'DT', 'Logistic Regression', 'Random Forest']\n",
    "    performanceHeaders = ['precision', 'recall', 'f1-score']\n",
    "    modPerformancePos = pd.DataFrame(index=methodsUsed, columns=performanceHeaders)\n",
    "    modPerformanceNeg = pd.DataFrame(index=methodsUsed, columns=performanceHeaders)\n",
    "\n",
    "    # Perform classification with SVM\n",
    "    print('Classification with SVM')\n",
    "    svm_clf = svm.SVC()\n",
    "    param_search_svm = {\n",
    "        'kernel': [\"poly\"],\n",
    "        'degree': [1, 2, 3, 4],\n",
    "        'coef0': [1, 2]\n",
    "    }\n",
    "    grid_search_svm = GridSearchCV(estimator=svm_clf, param_grid=param_search_svm, cv=5, verbose=1)\n",
    "    grid_search_svm.fit(train_vectors, trainSet['Positively Rated'])\n",
    "    best_clf_svm = grid_search_svm.best_estimator_\n",
    "    svm_prediction = best_clf_svm.predict(test_vectors)\n",
    "\n",
    "    df = pd.DataFrame(svm_prediction, columns=['SVM Prediction'])\n",
    "\n",
    "    # results report\n",
    "    report = classification_report(testSet['Positively Rated'], svm_prediction, output_dict=True)\n",
    "    positive = report['1']\n",
    "    dfpos = pd.DataFrame.from_dict(positive, columns=['positive'], orient='index')\n",
    "    negative = report['0']\n",
    "    dfneg = pd.DataFrame.from_dict(negative, columns=['negative'], orient='index')\n",
    "\n",
    "    print(dfpos)\n",
    "    print(\"\\n\")\n",
    "    print(dfneg)\n",
    "    print(\"\\n\")\n",
    "    print(\"accuracy: \", round(report['accuracy'], 2))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    modPerformancePos.iloc[0, 0] = dfpos.iloc[0, 0]\n",
    "    modPerformanceNeg.iloc[0, 0] = dfneg.iloc[0, 0]\n",
    "    modPerformancePos.iloc[0, 1] = dfpos.iloc[1, 0]\n",
    "    modPerformanceNeg.iloc[0, 1] = dfneg.iloc[1, 0]\n",
    "    modPerformancePos.iloc[0, 2] = dfpos.iloc[2, 0]\n",
    "    modPerformanceNeg.iloc[0, 2] = dfneg.iloc[2, 0]\n",
    "\n",
    "    # Perform classification with DT\n",
    "    print('Classification with DT')\n",
    "    dt_clf = DecisionTreeClassifier()\n",
    "    param_search_dt = {\n",
    "        'criterion': [\"gini\", 'entropy'],\n",
    "        'max_depth': [5, 10, 20, 30, None]\n",
    "    }\n",
    "    grid_search_dt = GridSearchCV(estimator=dt_clf, param_grid=param_search_dt, cv=5, verbose=1)\n",
    "    grid_search_dt.fit(train_vectors, trainSet['Positively Rated'])\n",
    "    best_clf_dt = grid_search_dt.best_estimator_\n",
    "    dt_prediction = best_clf_dt.predict(test_vectors)\n",
    "\n",
    "    df['DT Prediction'] = dt_prediction\n",
    "\n",
    "    # results report\n",
    "    report = classification_report(testSet['Positively Rated'], dt_prediction, output_dict=True)\n",
    "    positive = report['1']\n",
    "    dfpos = pd.DataFrame.from_dict(positive, columns=['positive'], orient='index')\n",
    "    negative = report['0']\n",
    "    dfneg = pd.DataFrame.from_dict(negative, columns=['negative'], orient='index')\n",
    "\n",
    "    print(dfpos)\n",
    "    print(\"\\n\")\n",
    "    print(dfneg)\n",
    "    print(\"\\n\")\n",
    "    print(\"accuracy: \", round(report['accuracy'], 2))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    modPerformancePos.iloc[1, 0] = dfpos.iloc[0, 0]\n",
    "    modPerformanceNeg.iloc[1, 0] = dfneg.iloc[0, 0]\n",
    "    modPerformancePos.iloc[1, 1] = dfpos.iloc[1, 0]\n",
    "    modPerformanceNeg.iloc[1, 1] = dfneg.iloc[1, 0]\n",
    "    modPerformancePos.iloc[1, 2] = dfpos.iloc[2, 0]\n",
    "    modPerformanceNeg.iloc[1, 2] = dfneg.iloc[2, 0]\n",
    "\n",
    "    # Perform classification with Logistic Regression\n",
    "    print('Classification with Logistic Regression')\n",
    "    lr_clf = LogisticRegression()\n",
    "    param_search_lr = {\n",
    "        'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'solver': ['lbfgs', 'saga']\n",
    "    }\n",
    "    grid_search_lr = GridSearchCV(estimator=lr_clf, param_grid=param_search_lr, cv=5, verbose=1)\n",
    "    grid_search_lr.fit(train_vectors, trainSet['Positively Rated'])\n",
    "    best_clf_lr = grid_search_lr.best_estimator_\n",
    "    lr_prediction = best_clf_lr.predict(test_vectors)\n",
    "\n",
    "    df['Logistic Regression Prediction'] = lr_prediction\n",
    "\n",
    "    # results report\n",
    "    report = classification_report(testSet['Positively Rated'], lr_prediction, output_dict=True)\n",
    "    positive = report['1']\n",
    "    dfpos = pd.DataFrame.from_dict(positive, columns=['positive'], orient='index')\n",
    "    negative = report['0']\n",
    "    dfneg = pd.DataFrame.from_dict(negative, columns=['negative'], orient='index')\n",
    "\n",
    "    print(dfpos)\n",
    "    print(\"\\n\")\n",
    "    print(dfneg)\n",
    "    print(\"\\n\")\n",
    "    print(\"accuracy: \", round(report['accuracy'], 2))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    modPerformancePos.iloc[2, 0] = dfpos.iloc[0, 0]\n",
    "    modPerformanceNeg.iloc[2, 0] = dfneg.iloc[0, 0]\n",
    "    modPerformancePos.iloc[2, 1] = dfpos.iloc[1, 0]\n",
    "    modPerformanceNeg.iloc[2, 1] = dfneg.iloc[1, 0]\n",
    "    modPerformancePos.iloc[2, 2] = dfpos.iloc[2, 0]\n",
    "    modPerformanceNeg.iloc[2, 2] = dfneg.iloc[2, 0]\n",
    "\n",
    "    # Perform classification with Random Forest\n",
    "    print('Classification with Random Forest')\n",
    "    rf_clf = RandomForestClassifier()\n",
    "    param_search_rf = {\n",
    "        'n_estimators': [10, 50, 100, 200],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "        'max_depth': [5, 10, 20, 30, None],\n",
    "        'max_leaf_nodes': [10, 20, 30, None]\n",
    "    }\n",
    "    grid_search_rf = GridSearchCV(estimator=rf_clf, param_grid=param_search_rf, cv=5, verbose=1)\n",
    "    grid_search_rf.fit(train_vectors, trainSet['Positively Rated'])\n",
    "    best_clf_rf = grid_search_rf.best_estimator_\n",
    "    rf_prediction = best_clf_rf.predict(test_vectors)\n",
    "\n",
    "    df['Random Forest Prediction'] = rf_prediction\n",
    "\n",
    "    # results report\n",
    "    report = classification_report(testSet['Positively Rated'], rf_prediction, output_dict=True)\n",
    "\n",
    "    # Comparing performance of the models\n",
    "    positive = report['1']\n",
    "    dfpos = pd.DataFrame.from_dict(positive, columns=['positive'], orient='index')\n",
    "    negative = report['0']\n",
    "    dfneg = pd.DataFrame.from_dict(negative, columns=['negative'], orient='index')\n",
    "\n",
    "    print(dfpos)\n",
    "    print(\"\\n\")\n",
    "    print(dfneg)\n",
    "    print(\"\\n\")\n",
    "    print(\"accuracy: \", round(report['accuracy'], 2))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    modPerformancePos.iloc[3, 0] = dfpos.iloc[0, 0]\n",
    "    modPerformanceNeg.iloc[3, 0] = dfneg.iloc[0, 0]\n",
    "    modPerformancePos.iloc[3, 1] = dfpos.iloc[1, 0]\n",
    "    modPerformanceNeg.iloc[3, 1] = dfneg.iloc[1, 0]\n",
    "    modPerformancePos.iloc[3, 2] = dfpos.iloc[2, 0]\n",
    "    modPerformanceNeg.iloc[3, 2] = dfneg.iloc[2, 0]\n",
    "\n",
    "    print(modPerformancePos)\n",
    "    print(\"\\n\")\n",
    "    print(modPerformanceNeg)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID  Sentiment                                           Sentence\n",
      "0            0          0  According to Gran , the company has no plans t...\n",
      "1            1          1  For the last quarter of 2010 , Componenta 's n...\n",
      "2            2          1  In the third quarter of 2010 , net sales incre...\n",
      "3            3          1  Operating profit rose to EUR 13.1 mn from EUR ...\n",
      "4            4          1  Operating profit totalled EUR 21.1 mn , up fro...\n",
      "...        ...        ...                                                ...\n",
      "108746  111290          1  Philippines president Rodrigo Duterte urges pe...\n",
      "108747  111291          1  Spain arrests three Pakistanis accused of prom...\n",
      "108748  111292          1  Venezuela, where anger over food shortages is ...\n",
      "108749  111293          1  A Hindu temple worker has been killed by three...\n",
      "108750  111294          1  Ozone layer hole seems to be healing - US &amp...\n",
      "\n",
      "[108751 rows x 3 columns]\n",
      "\n",
      "\n",
      "                                               Sentence  Positively Rated\n",
      "0     According to Gran , the company has no plans t...                 0\n",
      "1     For the last quarter of 2010 , Componenta 's n...                 1\n",
      "2     In the third quarter of 2010 , net sales incre...                 1\n",
      "3     Operating profit rose to EUR 13.1 mn from EUR ...                 1\n",
      "4     Operating profit totalled EUR 21.1 mn , up fro...                 1\n",
      "...                                                 ...               ...\n",
      "9995  Cracks are beginning to appear in the glass ce...                 0\n",
      "9996                                Pay now, save later                 0\n",
      "9997                               Confident of success                 0\n",
      "9998                             Home in on big rewards                 0\n",
      "9999              Retailers move onwards - and upwards?                 0\n",
      "\n",
      "[10000 rows x 2 columns]\n",
      "\n",
      "\n",
      "0.3495\n",
      "\n",
      "\n",
      "                                               Sentence  Positively Rated\n",
      "2967  Finnish management software solutions provider...                 0\n",
      "700   Yara Suomi Ltd also provides nitrogen chemical...                 0\n",
      "3481         Otherwise the situation is under control .                 0\n",
      "1621  LCS 's services cover the whole life cycle of ...                 0\n",
      "800   It also said its third quarter diluted EPS cam...                 1\n",
      "...                                                 ...               ...\n",
      "9225    ITN reporter 'bent over backwards for accuracy'                 1\n",
      "4859  Result before taxes decreased to nearly EUR 14...                 0\n",
      "3264                         Short on $ATVI from 24.55.                 0\n",
      "9845                             Reasons to be cheerful                 0\n",
      "2732  Completion of the transaction is subject to a ...                 0\n",
      "\n",
      "[7500 rows x 2 columns]\n",
      "trainSet shape:  (7500, 2)\n",
      "                                               Sentence  Positively Rated\n",
      "9394  Defector attacks Hague's 'repugnant' stance on...                 1\n",
      "898   After the sale , Savcor Group Ltd will compris...                 0\n",
      "2398  Full-year operating result for 2008 was 3.6 mi...                 0\n",
      "5906  $SBUX inverted head & shoulders pattern in the...                 1\n",
      "2343  The unit is planned to be operational during t...                 0\n",
      "...                                                 ...               ...\n",
      "8764          Crash course in chaos shocks the minister                 1\n",
      "4359  In 2010 , the Marimekko Group s net sales were...                 0\n",
      "2041  Elcoteq SE is Europe 's largest contract elect...                 0\n",
      "1108  A paper mill in the central Maine town of Madi...                 0\n",
      "3332  Qualcomm estimated a first-quarter profit betw...                 0\n",
      "\n",
      "[2500 rows x 2 columns]\n",
      "testSet shape:  (2500, 2)\n",
      "\n",
      "\n",
      "Classification with SVM\n",
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
      "             positive\n",
      "precision    0.782677\n",
      "recall       0.586777\n",
      "f1-score     0.670715\n",
      "support    847.000000\n",
      "\n",
      "\n",
      "              negative\n",
      "precision     0.812332\n",
      "recall        0.916515\n",
      "f1-score      0.861285\n",
      "support    1653.000000\n",
      "\n",
      "\n",
      "accuracy:  0.8\n",
      "\n",
      "\n",
      "Classification with DT\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "             positive\n",
      "precision    0.688503\n",
      "recall       0.608028\n",
      "f1-score     0.645768\n",
      "support    847.000000\n",
      "\n",
      "\n",
      "              negative\n",
      "precision     0.810502\n",
      "recall        0.859044\n",
      "f1-score      0.834068\n",
      "support    1653.000000\n",
      "\n",
      "\n",
      "accuracy:  0.77\n",
      "\n",
      "\n",
      "Classification with Logistic Regression\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "             positive\n",
      "precision    0.681758\n",
      "recall       0.604486\n",
      "f1-score     0.640801\n",
      "support    847.000000\n",
      "\n",
      "\n",
      "              negative\n",
      "precision     0.808462\n",
      "recall        0.855414\n",
      "f1-score      0.831276\n",
      "support    1653.000000\n",
      "\n",
      "\n",
      "accuracy:  0.77\n",
      "\n",
      "\n",
      "Classification with Random Forest\n",
      "Fitting 5 folds for each of 160 candidates, totalling 800 fits\n",
      "             positive\n",
      "precision    0.753754\n",
      "recall       0.592680\n",
      "f1-score     0.663582\n",
      "support    847.000000\n",
      "\n",
      "\n",
      "              negative\n",
      "precision     0.811887\n",
      "recall        0.900786\n",
      "f1-score      0.854029\n",
      "support    1653.000000\n",
      "\n",
      "\n",
      "accuracy:  0.8\n",
      "\n",
      "\n",
      "                    precision    recall  f1-score\n",
      "SVM                  0.782677  0.586777  0.670715\n",
      "DT                   0.688503  0.608028  0.645768\n",
      "Logistic Regression  0.681758  0.604486  0.640801\n",
      "Random Forest        0.753754   0.59268  0.663582\n",
      "\n",
      "\n",
      "                    precision    recall  f1-score\n",
      "SVM                  0.812332  0.916515  0.861285\n",
      "DT                   0.810502  0.859044  0.834068\n",
      "Logistic Regression  0.808462  0.855414  0.831276\n",
      "Random Forest        0.811887  0.900786  0.854029\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvNaturalLenguageProcessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
